# split_dataset.py
import os
import pickle
import argparse
import random
from tqdm.auto import tqdm

def main():
    """
    ä¸»å‡½æ•°ï¼Œç”¨äºåŠ è½½ã€åˆ†å‰²å’Œä¿å­˜æ•°æ®é›†ã€‚
    """
    parser = argparse.ArgumentParser(
        description="å°†æ•°æ®é›†æ–‡ä»¶(.pkl)æŒ‰ç…§æŒ‡å®šæ¯”ä¾‹åˆ†å‰²ä¸ºè®­ç»ƒé›†å’Œæµ‹è¯•é›†ã€‚"
    )
    parser.add_argument(
        '--input_path', 
        type=str, 
        required=True, 
        help="è¾“å…¥çš„å®Œæ•´æ•°æ®é›†.pklæ–‡ä»¶è·¯å¾„"
    )
    parser.add_argument(
        '--output_dir', 
        type=str, 
        required=True, 
        help="ä¿å­˜åˆ†å‰²åæ–‡ä»¶çš„è¾“å‡ºç›®å½•"
    )
    parser.add_argument(
        '--train_name', 
        type=str, 
        default='train_data.pkl', 
        help="è®­ç»ƒé›†è¾“å‡ºæ–‡ä»¶å (é»˜è®¤: train_data.pkl)"
    )
    parser.add_argument(
        '--test_name', 
        type=str, 
        default='test_data.pkl', 
        help="æµ‹è¯•é›†è¾“å‡ºæ–‡ä»¶å (é»˜è®¤: test_data.pkl)"
    )
    parser.add_argument(
        '--split_ratio', 
        type=float, 
        default=0.9, 
        help="è®­ç»ƒé›†æ‰€å çš„æ¯”ä¾‹ (é»˜è®¤: 0.9)"
    )
    parser.add_argument(
        '--seed', 
        type=int, 
        default=42, 
        help="ç”¨äºéšæœºæ‰“ä¹±çš„ç§å­ï¼Œç¡®ä¿ç»“æœå¯å¤ç° (é»˜è®¤: 42)"
    )
    args = parser.parse_args()

    # --- 1. è®¾ç½®éšæœºç§å­ä»¥ä¿è¯ç»“æœå¯å¤ç° ---
    print(f"ğŸŒ± ä½¿ç”¨éšæœºç§å­: {args.seed}")
    random.seed(args.seed)

    # --- 2. åŠ è½½åŸå§‹æ•°æ®é›† ---
    print(f"ğŸ”„ æ­£åœ¨ä» '{args.input_path}' åŠ è½½æ•°æ®...")
    try:
        with open(args.input_path, 'rb') as f:
            full_dataset = pickle.load(f)
        if not isinstance(full_dataset, list):
            raise TypeError("è¾“å…¥æ–‡ä»¶åº”åŒ…å«ä¸€ä¸ªPythonåˆ—è¡¨ (list)ã€‚")
        print(f"âœ… æ•°æ®åŠ è½½æˆåŠŸï¼Œå…±åŒ…å« {len(full_dataset)} ä¸ªæ ·æœ¬ã€‚")
    except FileNotFoundError:
        print(f"âŒ é”™è¯¯: è¾“å…¥æ–‡ä»¶æœªæ‰¾åˆ° '{args.input_path}'")
        return
    except Exception as e:
        print(f"âŒ åŠ è½½æ•°æ®æ—¶å‘ç”Ÿé”™è¯¯: {e}")
        return

    # --- 3. éšæœºæ‰“ä¹±æ•°æ®é›† ---
    print("ğŸ”€ æ­£åœ¨éšæœºæ‰“ä¹±æ•°æ®é›†...")
    random.shuffle(full_dataset)
    print("âœ… æ•°æ®é›†å·²æ‰“ä¹±ã€‚")

    # --- 4. è®¡ç®—åˆ†å‰²ç‚¹å¹¶åˆ†å‰²æ•°æ® ---
    num_total = len(full_dataset)
    num_train = int(num_total * args.split_ratio)
    
    train_set = full_dataset[:num_train]
    test_set = full_dataset[num_train:]

    print(f"âœ‚ï¸ æ•°æ®é›†åˆ†å‰²å®Œæˆ:")
    print(f"   - è®­ç»ƒé›†æ ·æœ¬æ•°: {len(train_set)}")
    print(f"   - æµ‹è¯•é›†æ ·æœ¬æ•°: {len(test_set)}")

    # --- 5. åˆ›å»ºè¾“å‡ºç›®å½•å¹¶ä¿å­˜æ–‡ä»¶ ---
    os.makedirs(args.output_dir, exist_ok=True)
    
    output_train_path = os.path.join(args.output_dir, args.train_name)
    output_test_path = os.path.join(args.output_dir, args.test_name)

    print(f"\nğŸ’¾ æ­£åœ¨ä¿å­˜è®­ç»ƒé›†è‡³ '{output_train_path}'...")
    with open(output_train_path, 'wb') as f:
        pickle.dump(train_set, f)
    print("âœ… è®­ç»ƒé›†ä¿å­˜æˆåŠŸã€‚")

    print(f"ğŸ’¾ æ­£åœ¨ä¿å­˜æµ‹è¯•é›†è‡³ '{output_test_path}'...")
    with open(output_test_path, 'wb') as f:
        pickle.dump(test_set, f)
    print("âœ… æµ‹è¯•é›†ä¿å­˜æˆåŠŸã€‚")

    print("\nğŸ‰ æ‰€æœ‰æ“ä½œå®Œæˆï¼")


if __name__ == '__main__':
    main()