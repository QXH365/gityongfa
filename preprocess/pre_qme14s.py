import os
import pickle
import copy
import glob
import random
import numpy as np
from scipy.signal import resample
from tqdm import tqdm

import torch
from torch_geometric.data import Data
from torch_geometric.transforms import Compose

import rdkit
from rdkit import Chem
from rdkit.Chem.rdchem import Mol, BondType
from rdkit import RDLogger
from transforms import AddHigherOrderEdges, CountNodesPerGraph

# ç¦ç”¨ RDKit çš„å†—ä½™æ—¥å¿—
RDLogger.DisableLog("rdApp.*")

# --- å…¨å±€å¸¸é‡å®šä¹‰ ---
BOND_TYPES = {t: i for i, t in enumerate(BondType.names.values())}

# --- è¾…åŠ©å‡½æ•° ---


# ã€ä¼˜åŒ–ã€‘å¦‚æœç»´åº¦åŒ¹é…ï¼Œæ­¤å‡½æ•°ç°åœ¨ä¼šç›´æ¥å¤åˆ¶è€Œä¸æ˜¯é‡é‡‡æ ·
def resample_spectrum(spectrum, target_len):
    """
    å¯¹å…‰è°±è¿›è¡Œé‡é‡‡æ ·è‡³ç›®æ ‡é•¿åº¦ã€‚
    å¦‚æœåŸå§‹é•¿åº¦ä¸ç›®æ ‡é•¿åº¦ç›¸åŒï¼Œåˆ™ç›´æ¥è½¬æ¢ç±»å‹è€Œä¸è¿›è¡Œé‡é‡‡æ ·ã€‚
    """
    spectrum_np = np.array(spectrum, dtype=np.float32)

    if spectrum_np.shape[0] == target_len:
        # ç»´åº¦åŒ¹é…ï¼Œç›´æ¥è¿”å›å¼ é‡å‰¯æœ¬
        return torch.from_numpy(spectrum_np)
    else:
        # ç»´åº¦ä¸åŒ¹é…ï¼Œæ‰§è¡Œé‡é‡‡æ ·
        resampled = resample(spectrum_np, target_len)
        return torch.tensor(resampled, dtype=torch.float32)


def canonicalize_smiles(smiles: str):
    """å°†SMILESå­—ç¬¦ä¸²è½¬æ¢ä¸ºå”¯ä¸€çš„è§„èŒƒå½¢å¼ã€‚"""
    mol = Chem.MolFromSmiles(smiles)
    if mol:
        return Chem.MolToSmiles(mol, canonical=True)
    return None


def parse_spectrum_csv_with_smiles(file_path: str):
    """è§£æåŒ…å«SMILESã€åŸå­åæ ‡å’Œå…‰è°±æ•°æ®çš„ç‰¹æ®ŠCSVæ–‡ä»¶ã€‚"""
    with open(file_path, "r") as f:
        lines = [line.strip() for line in f.readlines() if line.strip()]

    smiles = lines[0]
    coord_lines, spectrum_parts = [], []
    is_coord_section = True

    for line in lines[1:]:
        parts = line.split(",")
        if len(parts) == 4 and is_coord_section:
            try:
                _ = [float(p) for p in parts]
                coord_lines.append(parts)
            except ValueError:
                is_coord_section = False
                spectrum_parts.extend(p for p in parts if p)
        else:
            is_coord_section = False
            spectrum_parts.extend(p for p in parts if p)

    if not coord_lines or not spectrum_parts:
        raise ValueError(f"File {file_path} format error: missing coords or spectrum.")

    coords = np.array([list(map(float, line)) for line in coord_lines])
    z = torch.tensor(coords[:, 0], dtype=torch.long)
    pos = torch.tensor(coords[:, 1:], dtype=torch.float32)
    spectrum = [float(val) for val in spectrum_parts]

    return smiles, z, pos, spectrum


def create_mol_with_coords_from_smiles(smiles: str, true_coords: np.ndarray, true_elements: list) -> Mol:
    """é€šè¿‡å­ç»“æ„åŒ¹é…ï¼Œä»SMILESå’ŒåŸå­åæ ‡/ç±»å‹åˆ›å»ºå¯é çš„RDKitåˆ†å­å¯¹è±¡ã€‚"""
    try:
        template_mol = Chem.AddHs(Chem.MolFromSmiles(smiles))
        if template_mol.GetNumAtoms() != len(true_elements):
            return None

        query_mol = Chem.RWMol()
        for elem in true_elements:
            query_mol.AddAtom(Chem.Atom(elem))

        if sorted([a.GetSymbol() for a in template_mol.GetAtoms()]) != sorted(true_elements):
            return None

        match_indices = template_mol.GetSubstructMatch(query_mol.GetMol())
        if not match_indices:
            return None

        final_mol = copy.deepcopy(template_mol)
        conformer = Chem.Conformer(template_mol.GetNumAtoms())
        for query_idx, template_idx in enumerate(match_indices):
            pos = true_coords[query_idx].tolist()
            conformer.SetAtomPosition(template_idx, pos)
        final_mol.RemoveAllConformers()
        final_mol.AddConformer(conformer)
        return final_mol
    except Exception:
        return None


def rdmol_to_data(mol: Mol) -> Data:
    """å°†RDKitåˆ†å­å¯¹è±¡è½¬æ¢ä¸ºPyG Dataå¯¹è±¡ã€‚"""
    assert mol.GetNumConformers() == 1
    N = mol.GetNumAtoms()
    pos = torch.tensor(mol.GetConformer(0).GetPositions(), dtype=torch.float32)
    atomic_number = [atom.GetAtomicNum() for atom in mol.GetAtoms()]
    z = torch.tensor(atomic_number, dtype=torch.long)

    row, col, edge_type = [], [], []
    for bond in mol.GetBonds():
        start, end = bond.GetBeginAtomIdx(), bond.GetEndAtomIdx()
        row.extend([start, end])
        col.extend([end, start])
        edge_type.extend([BOND_TYPES.get(bond.GetBondType(), 0)] * 2)

    edge_index = torch.tensor([row, col], dtype=torch.long)
    edge_type = torch.tensor(edge_type, dtype=torch.long)

    if edge_index.numel() > 0:
        perm = (edge_index[0] * N + edge_index[1]).argsort()
        edge_index, edge_type = edge_index[:, perm], edge_type[perm]

    return Data(atom_type=z, pos=pos, edge_index=edge_index, edge_type=edge_type, rdmol=copy.deepcopy(mol))


def main():
    """ä¸»æ‰§è¡Œå‡½æ•°ï¼ŒåŒ…å«æ•°æ®å¤„ç†å’Œæ•°æ®é›†åˆ†å‰²ã€‚"""
    config = {
        "spectra_dirs": {
            "ir": "../../../dataset/qme14s/IR_broaden",
            "raman": "../../../dataset/qme14s/Raman_broaden",
        },
        "target_ir_len": 3500,
        "target_raman_len": 3500,
        "max_molecules": 10000000000,
        "model_edge_order": 3,
        # ã€æ–°å¢ã€‘æ•°æ®é›†åˆ†å‰²é…ç½®
        "output_dir": "qme14s_all",  # ä¿å­˜åˆ†å‰²åæ–‡ä»¶çš„è¾“å‡ºç›®å½•
        "split_ratios": {"train": 0.9, "val": 0, "test": 0.1},  # å°†æ­¤å€¼è®¾ä¸º 0 å¯ä»…åˆ’åˆ†è®­ç»ƒ/æµ‹è¯•é›†
        "seed": 42,  # ç”¨äºéšæœºæ‰“ä¹±çš„ç§å­ï¼Œç¡®ä¿ç»“æœå¯å¤ç°
    }

    # éªŒè¯æ¯”ä¾‹è®¾ç½®æ˜¯å¦åˆç†
    ratios = config["split_ratios"]
    assert (
        abs(ratios["train"] + ratios["val"] + ratios["test"] - 1.0) < 1e-8
    ), "é”™è¯¯ï¼štrain, val, test çš„æ¯”ä¾‹æ€»å’Œå¿…é¡»ä¸º 1ã€‚"
    assert ratios["train"] > 0 and ratios["test"] > 0, "é”™è¯¯ï¼štrain å’Œ test çš„æ¯”ä¾‹å¿…é¡»å¤§äº 0ã€‚"

    print("--- å¯åŠ¨æ•°æ®é›†é¢„å¤„ç†ä¸åˆ†å‰²æµç¨‹ ---")

    # --- æ­¥éª¤ 1: å®šä¹‰å›¾å˜æ¢æµç¨‹ ---
    print(f"\n[æ­¥éª¤ 1/3] å®šä¹‰å›¾å˜æ¢æµç¨‹...")
    graph_transforms = Compose([CountNodesPerGraph(), AddHigherOrderEdges(order=config["model_edge_order"])])
    print(" > æµç¨‹åˆ›å»ºæˆåŠŸã€‚")

    # --- æ­¥éª¤ 2: å¤„ç†åˆ†å­ã€å…‰è°±å¹¶åº”ç”¨å˜æ¢ ---
    print("\n[æ­¥éª¤ 2/3] æ­£åœ¨å¤„ç†åˆ†å­å’Œå…‰è°±æ•°æ®...")
    final_data_list = []
    ir_files = sorted(glob.glob(os.path.join(config["spectra_dirs"]["ir"], "IR_*.csv")))
    if config["max_molecules"] and len(ir_files) > config["max_molecules"]:
        ir_files = ir_files[: config["max_molecules"]]

    for ir_path in tqdm(ir_files, desc=" > æ­£åœ¨å¤„ç†åˆ†å­"):
        file_id = os.path.basename(ir_path).replace("IR_", "").replace(".csv", "")
        raman_path = os.path.join(config["spectra_dirs"]["raman"], f"Raman_{file_id}.csv")
        if not os.path.exists(raman_path):
            continue

        try:
            smiles, z, pos, raw_ir_spec = parse_spectrum_csv_with_smiles(ir_path)
            _, _, _, raw_raman_spec = parse_spectrum_csv_with_smiles(raman_path)

            ir_spec = resample_spectrum(raw_ir_spec, config["target_ir_len"])
            raman_spec = resample_spectrum(raw_raman_spec, config["target_raman_len"])

            elements = [Chem.GetPeriodicTable().GetElementSymbol(int(atom_num)) for atom_num in z]
            mol = create_mol_with_coords_from_smiles(smiles, pos.numpy(), elements)
            if not mol:
                continue

            base_data = rdmol_to_data(mol)
            transformed_data = graph_transforms(base_data)

            transformed_data.smiles = canonicalize_smiles(smiles)
            transformed_data.ir_spectrum = ir_spec
            transformed_data.raman_spectrum = raman_spec
            transformed_data.combined_spectrum = torch.cat([ir_spec, raman_spec], dim=0)
            transformed_data.sample_id = torch.tensor([int(file_id)], dtype=torch.long)

            final_data_list.append(transformed_data)
        except Exception as e:
            # print(f"è­¦å‘Š: å¤„ç† {os.path.basename(ir_path)} å¤±è´¥. é”™è¯¯: {e}")
            continue

    print(f"âœ… æ•°æ®å¤„ç†å®Œæˆï¼Œå…±è·å¾— {len(final_data_list)} ä¸ªæœ‰æ•ˆæ ·æœ¬ã€‚")

    # --- æ­¥éª¤ 3: åˆ†å‰²æ•°æ®é›†å¹¶ä¿å­˜ ---
    print(f"\n[æ­¥éª¤ 3/3] åˆ†å‰²å¹¶ä¿å­˜æ•°æ®é›†...")

    # è®¾ç½®éšæœºç§å­å¹¶æ‰“ä¹±æ•°æ®
    print(f"ğŸŒ± ä½¿ç”¨éšæœºç§å­: {config['seed']}")
    random.seed(config["seed"])
    random.shuffle(final_data_list)
    print("ğŸ”€ æ•°æ®é›†å·²éšæœºæ‰“ä¹±ã€‚")

    # è®¡ç®—åˆ†å‰²ç‚¹
    num_total = len(final_data_list)
    num_train = int(num_total * ratios["train"])

    # æ ¹æ®éªŒè¯é›†æ¯”ä¾‹å†³å®šåˆ†å‰²ç­–ç•¥
    if ratios["val"] > 0:
        num_val = int(num_total * ratios["val"])

        train_set = final_data_list[:num_train]
        val_set = final_data_list[num_train : num_train + num_val]
        test_set = final_data_list[num_train + num_val :]

        print(f"âœ‚ï¸ æ•°æ®é›†å·²åˆ†å‰²ä¸ºä¸‰éƒ¨åˆ†:")
        print(f"   - è®­ç»ƒé›†: {len(train_set)} ä¸ªæ ·æœ¬")
        print(f"   - éªŒè¯é›†: {len(val_set)} ä¸ªæ ·æœ¬")
        print(f"   - æµ‹è¯•é›†: {len(test_set)} ä¸ªæ ·æœ¬")

        sets_to_save = {"train.pkl": train_set, "val.pkl": val_set, "test.pkl": test_set}
    else:
        # ä»…åˆ†å‰²ä¸ºè®­ç»ƒé›†å’Œæµ‹è¯•é›†
        train_set = final_data_list[:num_train]
        test_set = final_data_list[num_train:]

        print(f"âœ‚ï¸ æ•°æ®é›†å·²åˆ†å‰²ä¸ºä¸¤éƒ¨åˆ† (æ— éªŒè¯é›†):")
        print(f"   - è®­ç»ƒé›†: {len(train_set)} ä¸ªæ ·æœ¬")
        print(f"   - æµ‹è¯•é›†: {len(test_set)} ä¸ªæ ·æœ¬")

        sets_to_save = {"train.pkl": train_set, "test.pkl": test_set}

    # åˆ›å»ºè¾“å‡ºç›®å½•å¹¶ä¿å­˜æ–‡ä»¶
    output_dir = config["output_dir"]
    os.makedirs(output_dir, exist_ok=True)

    for filename, dataset in sets_to_save.items():
        output_path = os.path.join(output_dir, filename)
        print(f"ğŸ’¾ æ­£åœ¨ä¿å­˜ {filename} è‡³ '{output_path}'...")
        with open(output_path, "wb") as f:
            pickle.dump(dataset, f)

    print("\nğŸ‰ æ‰€æœ‰æ“ä½œå®Œæˆï¼")


if __name__ == "__main__":
    main()
    RDLogger.EnableLog("rdApp.*")
